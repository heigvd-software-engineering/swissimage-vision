stages:
  # 1. Create tiles
  # 2. Pull annotations from S3
  # 3. Upload tiles + xml annotations to S3
  prepare:
    cmd: python3 src/0_prepare.py
    deps:
      - src/0_prepare.py
      - data/raw/swissBOUNDARIES3D_1_5_LV95_LN02.gpkg
    params:
      - prepare
    outs:
      - data/prepared/depends.txt

  # 1. Pull some images from S3
  # 2. Save them into DVC Cache
  preview:
    cmd: python3 src/1_preview.py
    deps:
      - src/1_preview.py
      - data/prepared/depends.txt
    params: 
      # We exclude
      #  - train.datamodule.num_workers
      #  - train.datamodule.pin_memory
      # as they should not invalidate the cache
      - train.datamodule.s3_data_path
      - train.datamodule.seed
      - train.datamodule.split
      - train.datamodule.batch_size
      - train.datamodule.image_size
    outs:
      - data/preview/samples
      - data/preview/depends.txt
  
  # Train the model
  train:
    cmd: python3 src/2_train.py
    deps:
      - src/2_train.py
      - data/preview/depends.txt
    params: 
      # We exclude
      #  - train.datamodule.num_workers
      #  - train.datamodule.pin_memory
      # as they should not invalidate the cache
      - train.datamodule.s3_data_path
      - train.datamodule.seed
      - train.datamodule.split
      - train.datamodule.batch_size
      - train.datamodule.image_size
      - train.model
      - train.training
    outs:
      - lightning_logs:
          persist: true
      - out/model.ckpt
  
  # Convert PyTorch model to BentoML model (TorchScript)
  export:
    cmd: python3 src/3_export.py
    deps:
      - src/3_export.py
      - out/model.ckpt
    params:
      - train.datamodule.batch_size
      - train.datamodule.image_size
      - export.model_name
    outs:
      - out/${export.model_name}.bentomodel

  # Evaluate the model
  evaluate:
    cmd: python3 src/4_evaluate.py
    deps:
      - src/4_evaluate.py
      - out/model.ckpt
    params: 
      # We exclude
      #  - train.datamodule.num_workers
      #  - train.datamodule.pin_memory
      # as they should not invalidate the cache
      - train.datamodule.s3_data_path
      - train.datamodule.seed
      - train.datamodule.split
      - train.datamodule.batch_size
      - train.datamodule.image_size
    outs:
      - data/evaluate
