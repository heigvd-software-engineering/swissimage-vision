bucket: swissimage-vision

# ------------------------------------------------------------------------
# DVC Pipeline Parameters
# ------------------------------------------------------------------------
prepare:
  src_bucket: swissimage-0.1m  # S3 bucket name
  s3_src_vrt_path: files.vrt  # S3 path to the VRT file
  s3_dest_prepared_path: data/prepared  # S3 path where to save the prepared data
  commune_name: Nyon     # Commune name to be cropped
  commune_x_ratio: 0.66  # Width ratio of the crop for the commune
  commune_y_ratio: 0.75  # Height ratio of the crop for the commune
  tile_size: 512        # Tile size cropped from the original image in pixels

preprocess:  # Empty for now

pre-train:
  datamodule:          # PyTorch Lightning DataModule parameters
    setup:
      # S3 path to the prepared data (should contain images/ and labels/ folders)
      seed: 42         # Random seed for data split
      split: 0.8       # train = split * total
      batch_size: 16
      image_size: 256  # Image size for the model
    num_workers: 6     # Split evenly between train and val dataloaders
    pin_memory: true
  model:
    seed: 64                # Random seed for model initialization
    num_classes: 1          # Solar panel
    freeze_backbone: false  # Freeze the backbone of the model
  training:
    lr: 0.00025
    lr_decay_rate: 0.0005
    lr_sched_step_size: 1  # Step size (epochs) for learning rate scheduler
    lr_sched_gamma: 0.7    # Multiplicative factor of learning rate decay
    save_ckpt: false       # Save best model checkpoint while training
    es_patience: null      # Early stopping patience, null to disable
    epochs: 5
    precision: "32-true"

train:
  datamodule:          # PyTorch Lightning DataModule parameters
    setup:
      # S3 path to the prepared data (should contain images/ and labels/ folders)
      seed: 42         # Random seed for data split
      split: 0.8       # train = split * total
      batch_size: 16
      image_size: 256  # Image size for the model
    num_workers: 6     # Split evenly between train and val dataloaders
    pin_memory: true
  model:
    seed: 42  # Random seed for model initialization
  training:
    lr: 0.05
    lr_decay_rate: 0.0005
    lr_sched_step_size: null  # Step size (epochs) for learning rate scheduler
    lr_sched_gamma: null      # Multiplicative factor of learning rate decay
    save_ckpt: false          # Save best model checkpoint while training
    es_patience: null         # Early stopping patience, null to disable
    epochs: 5
    precision: "32-true"

export:
  model_name: solar_model_gpu
